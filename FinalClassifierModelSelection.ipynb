{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75069b6d",
   "metadata": {},
   "source": [
    "<h1><strong><u>Final Model Selection (Assignment 5)</u></strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe1abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0402605",
   "metadata": {},
   "source": [
    "<h2><u>Data Loading</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b158988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"title\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa8eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting text files\n",
    "titles = []\n",
    "targets = []\n",
    "file_path_dict = {'clickbait': './clickbait_data.txt', 'non clickbait': './non_clickbait_data.txt'}\n",
    "for key, value in file_path_dict.items():\n",
    "    with open(value, 'r') as file:\n",
    "        for line_number, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                titles.append(line)\n",
    "                targets.append(key)\n",
    "data_dict = {\"title\": titles, \"target\": targets}\n",
    "df = pd.DataFrame(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dec939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK guinea pig farm to close after owner's fami...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18 Sweet Pumpkin Treats You Won't Believe Are ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Guy Just Did The Most Epic \"Cha Cha Slide\" D...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premium gas discounted for a few hours</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanctions on US products introduced by Brazil</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>Men, Stephen King Has A Really Important Messa...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>Greek government faces censure motion by oppos...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>15 Holiday Cocktails That Are Basically Dessert</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>This Corgi And Baby Are Best Friends And It's ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>Being In A Relationship During The Holidays: E...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         target\n",
       "0      UK guinea pig farm to close after owner's fami...  non clickbait\n",
       "1      18 Sweet Pumpkin Treats You Won't Believe Are ...      clickbait\n",
       "2      A Guy Just Did The Most Epic \"Cha Cha Slide\" D...      clickbait\n",
       "3                 Premium gas discounted for a few hours  non clickbait\n",
       "4          Sanctions on US products introduced by Brazil  non clickbait\n",
       "...                                                  ...            ...\n",
       "31995  Men, Stephen King Has A Really Important Messa...      clickbait\n",
       "31996  Greek government faces censure motion by oppos...  non clickbait\n",
       "31997    15 Holiday Cocktails That Are Basically Dessert      clickbait\n",
       "31998  This Corgi And Baby Are Best Friends And It's ...      clickbait\n",
       "31999  Being In A Relationship During The Holidays: E...      clickbait\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b649d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data[\"title\"]\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "display(X_train.shape) \n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70935af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        import re\n",
    "        en_stopwords = stopwords.words('english')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        new_text = text.lower() #lowercase\n",
    "\n",
    "        new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "\n",
    "        for word in new_text.split(): #remove stopwords\n",
    "            if word in en_stopwords:\n",
    "                new_text = new_text.replace(word, \"\")\n",
    "        \n",
    "        new_text = word_tokenize(new_text) #tokenize\n",
    "\n",
    "        new_text = [lemmatizer.lemmatize(token) for token in new_text] #lemmatize\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96710925",
   "metadata": {},
   "source": [
    "<h2><strong><u>Main Model Selection</u></strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc722d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 3/5] END ..........clf=BernoulliNB(alpha=1);, score=0.960 total time=   4.8s\n",
      "[CV 1/5] END ..........clf=BernoulliNB(alpha=1);, score=0.955 total time=   5.2s\n",
      "[CV 2/5] END ..........clf=BernoulliNB(alpha=1);, score=0.957 total time=   5.3s\n",
      "[CV 4/5] END ..........clf=BernoulliNB(alpha=1);, score=0.958 total time=   5.6s\n",
      "[CV 5/5] END ..........clf=BernoulliNB(alpha=1);, score=0.958 total time=   5.6s\n",
      "[CV 5/5] END clf=KNeighborsClassifier(n_neighbors=23);, score=0.929 total time=  11.4s\n",
      "[CV 2/5] END clf=KNeighborsClassifier(n_neighbors=23);, score=0.927 total time=  11.4s\n",
      "[CV 4/5] END clf=KNeighborsClassifier(n_neighbors=23);, score=0.923 total time=  11.5s\n",
      "[CV 1/5] END clf=KNeighborsClassifier(n_neighbors=23);, score=0.924 total time=  11.5s\n",
      "[CV 3/5] END clf=KNeighborsClassifier(n_neighbors=23);, score=0.925 total time=  11.5s\n",
      "[CV 4/5] END clf=MLPClassifier(alpha=1, hidden_layer_sizes=(14,));, score=0.942 total time=  28.2s\n",
      "[CV 5/5] END clf=MLPClassifier(alpha=1, hidden_layer_sizes=(14,));, score=0.937 total time=  28.4s\n",
      "[CV 3/5] END clf=MLPClassifier(alpha=1, hidden_layer_sizes=(14,));, score=0.937 total time=  29.1s\n",
      "[CV 1/5] END clf=MLPClassifier(alpha=1, hidden_layer_sizes=(14,));, score=0.934 total time=  35.7s\n",
      "[CV 2/5] END clf=MLPClassifier(alpha=1, hidden_layer_sizes=(14,));, score=0.942 total time=  30.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf': BernoulliNB(alpha=1)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(tokenizer=custom_tokenizer, token_pattern=None)),\n",
    "        (\"clf\", None)\n",
    "    ]\n",
    ")\n",
    "param_grid = {\n",
    "    \"clf\": [KNeighborsClassifier(n_neighbors=23), BernoulliNB(alpha=1), MLPClassifier(hidden_layer_sizes=(14,), alpha=1)]\n",
    "}\n",
    "model = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "model.fit(X_train, y_train)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead4530",
   "metadata": {},
   "source": [
    "<h2><u>Results</u></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fbed46",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li>What data representation did you use?</li>\n",
    "<p>The representation that I used for the data was the TF-IDF Vectorizer representation.</p></br>\n",
    "<li>What metric did you select to rank the models?</li>\n",
    "<p>The metric that I chose to rank the models was accuracy.</p></br>\n",
    "<li>How did each model score on the selected metric for both the training data and the testing data?</li>\n",
    "<p>Based on 'accuracy' the models scored on average:</p>\n",
    "<ol>\n",
    "<li><u>K-Nearest Neighbors</u></li>\n",
    "<ul>\n",
    "<li>Training - 93%</li>\n",
    "<li>Testing - 92%</li>\n",
    "</ul>\n",
    "<li><u>Naive Bayes</u></li>\n",
    "<ul>\n",
    "<li>Training - 96%</li>\n",
    "<li>Testing - 95%</li>\n",
    "</ul>\n",
    "<li><u>Multi-Layered Perceptron</u></li>\n",
    "<ul>\n",
    "<li>Training - 94%</li>\n",
    "<li>Testing - 93%</li>\n",
    "</ul>\n",
    "</ol>\n",
    "</br>\n",
    "<li>What hyperparameter values gave the optimal results in the cross validation?</li>\n",
    "<p>The hyperparameter values that gave the optimal results in the cross validation were the BernoulliNB classifier with a regularization coefficient of 1.</p></br>\n",
    "<li>Describe a way in which the classifier could be used as a plugin for a web browser.</li>\n",
    "<p>A way in which the classifier can be used as a plugin for a web browser is by first converting it into a format that can be ran in a browser such as an ONNX file. Next, a folder needs to be created to store the necessary files needed to build the browser extension. After the files have been created for the browser, the model inference needs to be implemented in the browser. Finally, the extension can be loaded and tested.</p></br>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
