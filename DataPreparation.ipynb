{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, PrecisionRecallDisplay, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV, validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"title\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting text files\n",
    "titles = []\n",
    "targets = []\n",
    "file_path_dict = {'clickbait': './clickbait_data.txt', 'non clickbait': './non_clickbait_data.txt'}\n",
    "for key, value in file_path_dict.items():\n",
    "    with open(value, 'r') as file:\n",
    "        for line_number, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                titles.append(line)\n",
    "                targets.append(key)\n",
    "data_dict = {\"title\": titles, \"target\": targets}\n",
    "df = pd.DataFrame(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a18a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK guinea pig farm to close after owner's fami...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18 Sweet Pumpkin Treats You Won't Believe Are ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Guy Just Did The Most Epic \"Cha Cha Slide\" D...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premium gas discounted for a few hours</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanctions on US products introduced by Brazil</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>Men, Stephen King Has A Really Important Messa...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>Greek government faces censure motion by oppos...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>15 Holiday Cocktails That Are Basically Dessert</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>This Corgi And Baby Are Best Friends And It's ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>Being In A Relationship During The Holidays: E...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         target\n",
       "0      UK guinea pig farm to close after owner's fami...  non clickbait\n",
       "1      18 Sweet Pumpkin Treats You Won't Believe Are ...      clickbait\n",
       "2      A Guy Just Did The Most Epic \"Cha Cha Slide\" D...      clickbait\n",
       "3                 Premium gas discounted for a few hours  non clickbait\n",
       "4          Sanctions on US products introduced by Brazil  non clickbait\n",
       "...                                                  ...            ...\n",
       "31995  Men, Stephen King Has A Really Important Messa...      clickbait\n",
       "31996  Greek government faces censure motion by oppos...  non clickbait\n",
       "31997    15 Holiday Cocktails That Are Basically Dessert      clickbait\n",
       "31998  This Corgi And Baby Are Best Friends And It's ...      clickbait\n",
       "31999  Being In A Relationship During The Holidays: E...      clickbait\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841526c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data[\"title\"]\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "display(X_train.shape) \n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dcaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        import re\n",
    "        en_stopwords = stopwords.words('english')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        new_text = text.lower() #lowercase\n",
    "\n",
    "        new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "\n",
    "        for word in new_text.split(): #remove stopwords\n",
    "            if word in en_stopwords:\n",
    "                new_text = new_text.replace(word, \"\")\n",
    "        \n",
    "        new_text = word_tokenize(new_text) #tokenize\n",
    "\n",
    "        new_text = [lemmatizer.lemmatize(token) for token in new_text] #lemmatize\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clickbait messages:  15999\n",
      "Number of non-clickbait messages:  16001\n"
     ]
    }
   ],
   "source": [
    "#Display message counts\n",
    "clickbait = data[(data['target'] == 'clickbait')]\n",
    "non_clickbait = data[(data['target'] == 'non clickbait')]\n",
    "clickbait_count = clickbait.value_counts().sum()\n",
    "non_clickbait_count = non_clickbait.value_counts().sum()\n",
    "total_messages = clickbait_count + non_clickbait_count\n",
    "spam_fraction = non_clickbait_count / total_messages\n",
    "\n",
    "print(\"Number of clickbait messages: \", clickbait_count)\n",
    "print(\"Number of non-clickbait messages: \", non_clickbait_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = make_scorer(precision_score, greater_is_better=True, pos_label='clickbait')\n",
    "recall = make_scorer(recall_score, greater_is_better=True, pos_label='clickbait')\n",
    "npv = make_scorer(precision_score, greater_is_better=True, pos_label='non clickbait')\n",
    "specificity = make_scorer(recall_score, greater_is_better=True, pos_label='non clickbait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = {'Accuracy': 'accuracy', 'Precision': precision, 'Recall': recall, 'Negative Predictive Value': npv, 'Specificity': specificity}\n",
    "lc_dict = {}\n",
    "vc_dict = {}\n",
    "cvs_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfa6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = y_train.unique()\n",
    "test_labels = y_test.unique()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
