{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fb6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, PrecisionRecallDisplay, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV, validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75be0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"title\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3cbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting text files\n",
    "titles = []\n",
    "targets = []\n",
    "file_path_dict = {'clickbait': './clickbait_data.txt', 'non clickbait': './non_clickbait_data.txt'}\n",
    "for key, value in file_path_dict.items():\n",
    "    with open(value, 'r') as file:\n",
    "        for line_number, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                titles.append(line)\n",
    "                targets.append(key)\n",
    "data_dict = {\"title\": titles, \"target\": targets}\n",
    "df = pd.DataFrame(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a18a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everyone Stop And Appreciate Zac Efron Touchin...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are You Ready To Sync Your Vagina With Your Sm...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 Insanely Delicious Things To Make With 3 In...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGM Mirage Reaches Deal on Las Vegas Project</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Is Why Soy Milk Goes Funny In Your Coffee</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>Police Chief Plays Down I.R.A. Groups in Ulster</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>Demi Lovato Performs Next To Giant Boner</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>Regular People Try To Catch Passes From An NFL...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>This Is Why You Don't Fuck With A Crocodile</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>First supernova seen during explosion breakout</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         target\n",
       "0      Everyone Stop And Appreciate Zac Efron Touchin...      clickbait\n",
       "1      Are You Ready To Sync Your Vagina With Your Sm...      clickbait\n",
       "2      25 Insanely Delicious Things To Make With 3 In...      clickbait\n",
       "3           MGM Mirage Reaches Deal on Las Vegas Project  non clickbait\n",
       "4         This Is Why Soy Milk Goes Funny In Your Coffee      clickbait\n",
       "...                                                  ...            ...\n",
       "31995    Police Chief Plays Down I.R.A. Groups in Ulster  non clickbait\n",
       "31996           Demi Lovato Performs Next To Giant Boner      clickbait\n",
       "31997  Regular People Try To Catch Passes From An NFL...      clickbait\n",
       "31998        This Is Why You Don't Fuck With A Crocodile      clickbait\n",
       "31999     First supernova seen during explosion breakout  non clickbait\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841526c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data[\"title\"]\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "display(X_train.shape) \n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dcaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        import re\n",
    "                # Get stopwords function and Word Lemmatizer\n",
    "        en_stopwords = stopwords.words('english')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        # Process text\n",
    "        new_text = text.lower() #lowercase\n",
    "        new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "        new_text = word_tokenize(new_text) #tokenize\n",
    "        for word in new_text: #remove stopwords\n",
    "            if word in en_stopwords:\n",
    "                new_text.remove(word)\n",
    "        new_text = [lemmatizer.lemmatize(token) for token in new_text] #lemmatize\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb3e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clickbait messages:  15999\n",
      "Number of non-clickbait messages:  16001\n"
     ]
    }
   ],
   "source": [
    "#Display message counts\n",
    "clickbait = data[(data['target'] == 'clickbait')]\n",
    "non_clickbait = data[(data['target'] == 'non clickbait')]\n",
    "clickbait_count = clickbait.value_counts().sum()\n",
    "non_clickbait_count = non_clickbait.value_counts().sum()\n",
    "total_messages = clickbait_count + non_clickbait_count\n",
    "spam_fraction = non_clickbait_count / total_messages\n",
    "\n",
    "print(\"Number of clickbait messages: \", clickbait_count)\n",
    "print(\"Number of non-clickbait messages: \", non_clickbait_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89dc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = make_scorer(precision_score, greater_is_better=True, pos_label='clickbait')\n",
    "recall = make_scorer(recall_score, greater_is_better=True, pos_label='clickbait')\n",
    "npv = make_scorer(precision_score, greater_is_better=True, pos_label='non clickbait')\n",
    "specificity = make_scorer(recall_score, greater_is_better=True, pos_label='non clickbait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893fbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = {'Accuracy': 'accuracy', 'Precision': precision, 'Recall': recall, 'Negative Predictive Value': npv, 'Specificity': specificity}\n",
    "lc_dict = {}\n",
    "vc_dict = {}\n",
    "cvs_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dfa6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = y_train.unique()\n",
    "test_labels = y_test.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
